This section covers a major contribution of this thesis, related to the design
and implementation of a semi-synthetic dataset generator to be used by
convolutional neural networks.

\subsection{Problem statement}

To properly train a convolutional neural network, it is crucial to collect a
balanced dataset representing all possible cases to produce a robust and
stable model. This task can be tedious, especially for the case of supervised
learning where each sample must be annotated with the desired learned output.\\

The use of synthetic datasets in deep learning, and more specifically in
computer vision, is not common but neither unheard-of. An early work from
Vasquez \etal~\cite{PedestrianDetection} presented a study of the use computer
graphics to render virtual scenes and images of pedestrians, and the potential
adaptation for real-world usage of classifiers trained on such synthetic
dataset. Even though the approach is based on engineered feature detection
methods (such as HOG -- Histogram Of Gradients), and not deep convolutions, the
final statement is still valid: there is a noticeable domain shift for
classifiers trained on virtual-world data, only just as there would be with
real-world data.

Another work, from Cheung \etal~\cite{CheungWBM17}, introduced a novel method
for synthetic pedestrians integration on unannotated real-world background
images. The novelty lies in the fact that since no annotations are used for the
background dataset, they developed an algorithm to calibrate the virtual
camera, compute the right pedestrians scale and infer a ``Spawn Probability
Map'' from features in the image. This method allows them to overlay synthetic
pedestrians onto any background image, while respecting the scale of the
environment and the obstacles depicted in the picture.\\


For the specific case of autonomous drone racing however, no occurrence of the
use of synthetic datasets for the perception logic could be found, at the time
of this writing. What emerged from the literature review of the past research
in this field, is that most deep learning-based methods make use of manually
collected image datasets, mostly captured from a drone piloted by a human.

Unfortunately, this kind of dataset is limited in the fact that it cannot be
reused by other researchers without possessing the same obstacles, or the same
environment represented in it. The same goes for the annotations, and the
sensors used, which cannot be modified or enhanced without corrupting the
dataset integrity. To sum up, most researchers need to create their own dataset
when it comes to autonomous drone racing, simply because they have different
needs in terms of data input and ground truth.\\

