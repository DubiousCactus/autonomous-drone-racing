\chapter{Conclusion}

Over the course of this project, a hypothesis on the use of synthetic images,
to solve the gate detection challenge in drone racing, is proposed and put
to the test. This idea presents a risk, given the fact that the use of
mixed-reality images in deep learning for drone racing is unprecedented.
However, the technique of combining computer generated imagery with real-world
photographs for the training of deep learning models is not unheard-of and it
has been applied in several researches, showing promising results.

To begin with, a complete semi-synthetic dataset generation pipeline is
implemented, and the realism of its product is analyzed and discussed.
This method's results are tested on two different image recognition models for
embedded applications.
For both models' experiments, transfer learning is used to try
different adjustments to the base topology of the network, as to establish a
benchmark of empirical scores.
DroNet is the first model to train on this semi-synthetic dataset, as it is
designed primarily for autonomous drone navigation. Even though the initial
results prove the method to be functional, they expose severe symptoms of
overfitting and showe the model's inability to learn a generalized objective
function for the problem. Several regularization techniques are applied, but
only delay the problem and do not actually solve it. In an attempt to bypass
this impeding issue, a more generalized model, MobileNetV2, is adopted. Even
though early signs of overfitting are still present during the training of
this model, the right regularization techniques are applied, and the problem is
then considered solved. Nevertheless, evaluating the model on real-world test
images exposes a strong overfitting of the network on another level:
MobileNetV2 can categorize inputs to a great extent, but it is unfortunately
unable to detect any physical gates in real conditions. To overcome this
problem, a heavy image augmentation pipeline is added to the training routine.
By applying random amounts of motion blur and other image distortions, the
network is able to learn a generalized representation of the data, and can
perform significantly better than DroNet on real images.

In order to proceed further with the evaluation of this method's viability, a
simple yet efficient flight controller is designed, based on a PID controller
and a supervision state machine to handle the decision-making along the track. 
Surprisingly, deciding when to cross the targeted gate turns out to be the
most difficult piece of logic to design for the state machine. This is due to
the instability of the predictions provided by the perception node when the
camera becomes too close to the obstacle, and therefore does not perceive it
clearly. With more time allocated for this research, a proper path planning
and control scheme for the drone could be designed and implemented, which might
take better advantage of the proposed solution for the perception.

In the end, the entire autonomous system developed during this work is tested
in real conditions. It is able to successfully cross several gates of
different shapes and colors, only one at a time. The result of those
experiments show the viability of the proposed method, and even though no
valuable test metrics are provided, a subjective evaluation of the system's
performance can be considered. This work shows promising results for drone
racing, and this innovative idea should empower researchers to more actively
develop control algorithms based on such simple, yet flexible, approach to
perception.
