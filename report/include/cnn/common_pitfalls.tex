\subsection{Common pitfalls}

Among other issues such as the vanishing and exploding gradient problems
discussed earlier, strongly recurring themes are observed during the training
phase of deep learning models, especially in computer vision applications where
networks deal with high dimensional data.

	\subsubsection{Underfitting}
The very first challenge to overcome when training a neural network, is its
unability to optimize its objective function, or minimize its cost function,
often called \emph{underfitting}.

Even before evaluating a model to a validation set, it is primordial to obtain
decent performance on the training dataset. A good and objective metric to
monitor the efficiency of a model is the accuracy percentage, defined as:

\begin{equation}
	\frac{TP+TN}{TP+TN+FP+FN}
\end{equation}

with $TP$ and $TN$ being the number of \emph{true positives} and \emph{true
negatives}, and $FP$ and $FN$ being the amount of \emph{false positives} and
\emph{false negatives}.\\

A model that is able to fit to a training set should see its training accuracy
(measured over the said dataset) progressively rising, and converging to a
decent value. In theory, if a network has the capacity to learn and optimize
over a given objective function, its accuracy should converge to 100\%, given
that no data augmentation is applied, and that the problem is solvable. In
practice however, a model can have difficulties minimizing its cost function,
due to an unbalanced dataset or a highly complex objective function to fit for
instance, but should still be able to converge to a satisfyable accuracy.\\

In order to solve the overfitting impasse, it is important to verify the
possible presence of problems specified above. Most of the time, if a network
is unable to learn, it is caused by a malformed dataset or objective function,
or even errors in the ground truth. To eliminate most likely causes, it is
reasonable to try and solve the same problem, in the same conditions, with a
different model, preferably known to have good performances.\\

Once this issue has been dealt with, it lays a good fundation to start
evaluating the performance of the model on data it has not seen before.

	\subsubsection{Overfitting}
