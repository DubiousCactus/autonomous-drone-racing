\subsection{Common pitfalls}

Among other issues such as the vanishing and exploding gradient problems
discussed earlier, strongly recurring themes are observed during the training
phase of deep learning models, especially in computer vision applications where
networks deal with high dimensional data.

	\subsubsection{Underfitting}
The very first challenge to overcome when training a neural network, is its
inability to optimize its objective function, or minimize its cost function,
often called \emph{underfitting}.

Even before evaluating a model to a validation set, it is primordial to obtain
decent performance on the training dataset. A good and objective metric to
monitor the efficiency of a model is the accuracy percentage, defined as:

\begin{equation}
	\frac{TP+TN}{TP+TN+FP+FN}
\end{equation}

with $TP$ and $TN$ being the number of \emph{true positives} and \emph{true
negatives}, and $FP$ and $FN$ being the amount of \emph{false positives} and
\emph{false negatives}.\\

A model that is able to fit to a training set should see its training accuracy
(measured over the said dataset) progressively rising, and converging to a
decent value. In theory, if a network has the capacity to learn and optimize
over a given objective function, its accuracy should converge to 100\%, given
that no data augmentation is applied, and that the problem is solvable. In
practice however, a model can have difficulties minimizing its cost function,
due to an unbalanced dataset or a highly complex objective function to fit for
instance, but should still be able to converge to a satisfyable accuracy.\\

In order to solve the overfitting impasse, it is important to verify the
possible presence of problems specified above. Most of the time, if a network
is unable to learn, it is caused by a malformed dataset or objective function,
or even errors in the ground truth. To eliminate most likely causes, it is
reasonable to try and solve the same problem, in the same conditions, with a
different model, preferably known to have good performances.\\

Once this issue has been dealt with, a good fundation is laid to start
evaluating the performance of the model on data it has not seen before.

	\subsubsection{Overfitting}

A much more difficult pitfall to overcome is the ineptitude of a model to learn
a generalized representation of the data, also known as \emph{overfitting}.

Even though the training loss of a network is converging, and its accuracy
measure is following, the model might have learnt a perfect mapping of the
training data only, and therefore unable to provide accurate predictions on
previously unseen data. The validation dataset is specificaly used to verify
this assumption, by evaluating the model at the end of each iteration, and
expecting an overall decrease of the cost function.

Nevertheless, it is often the case that a gap is observed between the training
and validation metrics, simply because of the dataset size difference and also
the fact that the network will obviously perform better on the data it has been
learning with. However, if that gap is widening over significant amount of
training iterations, one can consider the case of overfitting, and conclude
that the model is not generalizing its learning.\\

Naturally, overfitting can be -- in most cases -- sovled by feeding more
training samples to the network, if that is an available option. On the other
hand, if the dataset is limited in size, data augmentation techniques can be
employed to artificially enlarge the training set, and provide modified
samples, usually based on channel shifts and image distortions, as long as the
ground truth remains valid. The afformentioned regularization methods are also
common solutions to overfit models.
