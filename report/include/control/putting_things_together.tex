\section{Putting things together}

As stated previously, the controller is implemented as a ROS node, and
subscribes to two topics:
\begin{itemize}
	\item{\textbf{/mavros/local\_position/velocity}, which is the local velocity
	of the drone, published by the low-level controller. This information is
	used to compute the error derivative in the PID controller.}
	\item{\textbf{/predictor/filtered}, the gate center predictions, to which a
	median filter is applied in an attempt to get rid of outliers. The output
	is an integer representing the region proposal window.}
\end{itemize}

~\\In addition, it publishes the desired velocity to the
\textbf{/IntelDrone/command\_velocity\_body} ROS topic, where a separated node
is subscribed. This node is responsible for the safety of the drone during the
tests: it creates a virtual cage via the motion capture system, and uses a
closed feedback loop to locate the drone and prevent it from stepping outside
that cage. Other types of safety features, such as commanded velocity
thresholding, are implemented.\\

The main function, which runs the state machine itself, is running at 100Hz,
while the gate center detection is locally refreshed at 33Hz.
Figure~\ref{fig:state} shows the complete finite state machine responsible for
coordinating the drone's sensing and planning, in the different stages of the
race.

\begin{figure}[h]
	\centering
	\input{include/control/finite_state_machine.tex}
	\caption{State diagram of the controller. \textcolor{red}{Add the velocity
	commnands at each state!}}
	\label{fig:state}
\end{figure}

In each of the states depicted in figure~\ref{fig:state}, specific commands are
issued, and certain conditions are verified. The \emph{ready} condition is a
simple flag that is set to \texttt{True} whenever a new prediction is published
from the gate center detection node, and reset to \texttt{False} when it is
used. That way, the drone does not fly blindly and has to wait if the
perception stops working.

The most important part of the logic is the \emph{crossing\_condition} which,
when met, switches the state from \texttt{REFINING} to \texttt{CROSSING}.

In effect, the most difficult challenge to solve in the gate crossing process,
is to actually decide when it is a good time to engage. As the drone
approaches the gate, the latter begins to occupy more space on the image, and
eventually vanishes entirely. Solving this issue is not as simple as detecting
a falling edge in the gate detection signal, mainly because of the lack of
precision and robustness of the model. Indeed, as the gate gets closer to the
camera, the center prediction becomes jittery and unreliable.\\

As an attempt to bypass the problem, a number of past predictions is kept in
memory (e.g. 10), and a set of acceptable regions is set, which correspond to
the window predictions that are deemed ``valid'' and are supposedly within the
center of the gate (e.g. \{8, 12, 13, 14\}). The following pseudo-code evaluates
the crossing condition:

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\begin{algorithm}
	\caption{Crossing condition evaluation}\label{alg:crosscond}
	\begin{algorithmic}[1]
		\Procedure{CrossingCondition}{}
			\State $\textit{acceptableRegions} \gets \{8, 12, 13, 14\}$
			\State $crossing \gets \texttt{True}$
			\State $p \gets \text{getPrediction()}$
			\State $previousPredictionsCount \gets \text{length of }
				\textit{previousPredictions}$
			~\\
			\If {$previousPredictionsCount < 10 \lor p\in acceptableRegions$}
				\Return \texttt{False}
			\EndIf

			\ForAll{$\textit{previousPredictions} \text{ as } \textit{previous\_p}$}
				\If {$\textit{previous\_p} \notin \textit{acceptableRegions}$}
					\State $crossing \gets \texttt{False}$
					\State \textbf{break}
				\EndIf
			\EndFor

			\Return $\textit{crossing}$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Obviously, it is not an optimal solution as it requires to manually set the
valid predictions, which does not scale to different amounts of windows.
Ideally, the prediction model would be robust enough that with some filtering,
a simple falling edge could engage the drone to cross the gate.\\

On a last note, the autonomous system was tested in real conditions, and was
able to detect, target and successfully cross different gates of different
shapes and colors, among a few failures. Since the performance of the PID
controller cannot be evaluated and rigorously tested without spending more time
and effort on a ground truth trajectory creation pipeline for the autonomous
flight, the reader must take this subjective conclusion for granted.
